{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on Covid-19 tweets with machine learning classifiers\n",
    "\n",
    "Classify 45k tweets on Covid-19 as positive or negative based on the following machine learning models: \n",
    "\n",
    "* Multinomial Naive Bayes Model\n",
    "* Random Forests \n",
    "* ADABoost\n",
    "* XGBoost\n",
    "\n",
    "The tweets are preprocessed using the following NLP methods: \n",
    "\n",
    "* Bag-of-words model\n",
    "* Bag-of-POS model\n",
    "* Pre-trained word embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import collections\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from tune_sklearn import TuneGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    # convert to lowercase, susbstitute non alphanumerical characters with whitespaces\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model, X_test): \n",
    "    ''' Given a fitted model and a test set, returns optimal hyperparameters, AUC and accuracy '''\n",
    "    clf_b = model.best_estimator_\n",
    "    y_pred_proba = clf_b.predict_proba(X_test)\n",
    "    y_pred = clf_b.predict(X_test)\n",
    "\n",
    "    # performance metrics\n",
    "    auc_res=roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return (model.best_params_, auc_res, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analytics\n",
    "\n",
    "* There are no duplicated values in the dataset\n",
    "* Missing values only in the location feature\n",
    "* Most tweets have positive sentiment\n",
    "* On average, each tweet has about 30 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"./Corona_NLP_train.csv\",encoding=\"latin1\")\n",
    "test_data=pd.read_csv(\"./Corona_NLP_test.csv\",encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44955, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge train and test datasets\n",
    "df = pd.concat([train_data, test_data], axis = 0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicated tweets\n",
    "duplicates = df[df.duplicated()]\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName            0\n",
       "ScreenName          0\n",
       "Location         9424\n",
       "TweetAt             0\n",
       "OriginalTweet       0\n",
       "Sentiment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sentiment'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df.groupby(\"Sentiment\")[\"Sentiment\"].agg(\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "counts.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative', 'Extremely Positive', 'Extremely Negative'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove neutral tweets\n",
    "df.drop(df[df.Sentiment == \"Neutral\"].index, inplace = True)\n",
    "\n",
    "df.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate extremely positive/negative values\n",
    "df = df.replace(\"Extremely Positive\", \"Positive\")\n",
    "df = df.replace(\"Extremely Negative\", \"Negative\")\n",
    "\n",
    "df.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sentiment'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df.groupby(\"Sentiment\")[\"Sentiment\"].agg(\"count\")\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "counts.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName              Location     TweetAt  \\\n",
       "1      3800       48752                    UK  16-03-2020   \n",
       "2      3801       48753             Vagabonds  16-03-2020   \n",
       "3      3802       48754                   NaN  16-03-2020   \n",
       "6      3805       48757  35.926541,-78.753267  16-03-2020   \n",
       "8      3807       48759       Atlanta, GA USA  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "1  advice Talk to your neighbours family to excha...  Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...  Positive  \n",
       "3  My food stock is not the only one which is emp...  Positive  \n",
       "6  Cashier at grocery store was sharing his insig...  Positive  \n",
       "8  Due to COVID-19 our retail store and classroom...  Positive  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment  word_count\n",
       "1  advice Talk to your neighbours family to excha...  Positive          38\n",
       "2  Coronavirus Australia: Woolworths to give elde...  Positive          14\n",
       "3  My food stock is not the only one which is emp...  Positive          40\n",
       "6  Cashier at grocery store was sharing his insig...  Positive          28\n",
       "8  Due to COVID-19 our retail store and classroom...  Positive          46"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of words per headline. strip whitespaces at the beginning/end of the sentence \n",
    "# and tokenize by whitespace\n",
    "df_select = df[[\"OriginalTweet\", \"Sentiment\"]]\n",
    "df_select[\"word_count\"] = df_select[\"OriginalTweet\"].apply(lambda x: len(x.strip().split(\" \")))\n",
    "df_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35555.000000\n",
       "mean        32.130108\n",
       "std         11.063108\n",
       "min          1.000000\n",
       "25%         24.000000\n",
       "50%         33.000000\n",
       "75%         41.000000\n",
       "max        127.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics of word counts\n",
    "df_select[\"word_count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distributions of word counts by sentiment\n",
    "pos = df_select[df_select.Sentiment == \"Positive\"].word_count\n",
    "neg =  df_select[df_select.Sentiment == \"Negative\"].word_count\n",
    "\n",
    "plt.hist(pos, bins = 20, alpha = 0.5, label='positive')\n",
    "plt.hist(neg, bins = 20, alpha = 0.5, label='negative')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>With Gov Hogan's announcement that all bars, r...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>@RicePolitics @MDCounties Craig, will you call...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35555 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          OriginalTweet Sentiment  word_count\n",
       "1     advice Talk to your neighbours family to excha...  Positive          38\n",
       "2     Coronavirus Australia: Woolworths to give elde...  Positive          14\n",
       "3     My food stock is not the only one which is emp...  Positive          40\n",
       "6     Cashier at grocery store was sharing his insig...  Positive          28\n",
       "8     Due to COVID-19 our retail store and classroom...  Positive          46\n",
       "...                                                 ...       ...         ...\n",
       "3791  With Gov Hogan's announcement that all bars, r...  Negative          43\n",
       "3792  @RicePolitics @MDCounties Craig, will you call...  Negative          29\n",
       "3793  Meanwhile In A Supermarket in Israel -- People...  Positive          18\n",
       "3796  Gov need to do somethings instead of biar je r...  Negative          29\n",
       "3797  I and @ForestandPaper members are committed to...  Positive          34\n",
       "\n",
       "[35555 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "df_select.to_csv(\"binary_data.csv\",index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Preprocessing\n",
    "\n",
    "## Basic preprocessing: \n",
    "\n",
    "* Convert tweets to lowercase\n",
    "* Remove punctuation and non alphanumerical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"binary_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If there's an elderly person/couple that cant make it to the grocery store or simply doesn't want to go, I'd be happy to go for you.\\r\\r\\n\\r\\r\\nIf you know someone in need in or around Lewisville/Frisco please DM me and well try to figure this out.\\r\\r\\n\\r\\r\\n#coronavirus\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select random tweet\n",
    "text = df.OriginalTweet.iloc[400]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>38</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>40</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>28</td>\n",
       "      <td>cashier at grocery store was sharing his insig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46</td>\n",
       "      <td>due to covid 19 our retail store and classroom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet Sentiment  word_count  \\\n",
       "0  advice Talk to your neighbours family to excha...  Positive          38   \n",
       "1  Coronavirus Australia: Woolworths to give elde...  Positive          14   \n",
       "2  My food stock is not the only one which is emp...  Positive          40   \n",
       "3  Cashier at grocery store was sharing his insig...  Positive          28   \n",
       "4  Due to COVID-19 our retail store and classroom...  Positive          46   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  advice talk to your neighbours family to excha...  \n",
       "1  coronavirus australia woolworths to give elder...  \n",
       "2  my food stock is not the only one which is emp...  \n",
       "3  cashier at grocery store was sharing his insig...  \n",
       "4  due to covid 19 our retail store and classroom...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess entire corpus\n",
    "df['tweet_clean'] = df['OriginalTweet'].apply(preprocessor)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of- models\n",
    "\n",
    "Bag-of- models are used to produce a real-valued representation of a text document that can used to train a ML model.\n",
    "\n",
    "* Bag-of-words: count (with normalization) the occurences of each token in a text\n",
    "* Bag-of-POS: count the occurence of each POS tag in a text. A POS is a set of words with similar sytactic behaviour (nouns, adjective, verbs, pronouns etc). POS tags are assigned to every word in a document and used in bag-of machine learning models. \n",
    "\n",
    "Bag-of-word models suffer from high dimensionality and sparseness of the real-valued representation. Bag-of-POS is usually more parsimonious than bag-of-words, since there usually are less POS-tags than words in a document, and can therefore be used to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [advice, talk, to, your, neighbours, family, t...\n",
       "1        [coronavirus, australia, woolworths, to, give,...\n",
       "2        [my, food, stock, is, not, the, only, one, whi...\n",
       "3        [cashier, at, grocery, store, was, sharing, hi...\n",
       "4        [due, to, covid, 19, our, retail, store, and, ...\n",
       "                               ...                        \n",
       "35550    [with, gov, hogan, s, announcement, that, all,...\n",
       "35551    [ricepolitics, mdcounties, craig, will, you, c...\n",
       "35552    [meanwhile, in, a, supermarket, in, israel, pe...\n",
       "35553    [gov, need, to, do, somethings, instead, of, b...\n",
       "35554    [i, and, forestandpaper, members, are, committ...\n",
       "Name: tweet_clean, Length: 35555, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the dataset with nltk tokenizer\n",
    "text_processed = df.tweet_clean.apply( word_tokenize )\n",
    "text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [(advice, NN), (talk, NN), (to, TO), (your, PR...\n",
       "1        [(coronavirus, NN), (australia, NNS), (woolwor...\n",
       "2        [(my, PRP$), (food, NN), (stock, NN), (is, VBZ...\n",
       "3        [(cashier, NN), (at, IN), (grocery, NN), (stor...\n",
       "4        [(due, JJ), (to, TO), (covid, VB), (19, CD), (...\n",
       "                               ...                        \n",
       "35550    [(with, IN), (gov, JJ), (hogan, NNS), (s, VBP)...\n",
       "35551    [(ricepolitics, NNS), (mdcounties, NNS), (crai...\n",
       "35552    [(meanwhile, RB), (in, IN), (a, DT), (supermar...\n",
       "35553    [(gov, NNS), (need, VBP), (to, TO), (do, VB), ...\n",
       "35554    [(i, NN), (and, CC), (forestandpaper, JJ), (me...\n",
       "Name: tweet_clean, Length: 35555, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS-tags for the whole dataset\n",
    "text_tagged = text_processed.apply(pos_tag)\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NN-NN-TO-PRP$-NNS-NN-TO-VB-NN-NNS-VBP-JJ-NN-IN...\n",
       "1        NN-NNS-NNS-TO-VB-RB-VBN-VBN-NN-NNS-IN-JJ-CD-JJ...\n",
       "2        PRP$-NN-NN-VBZ-RB-DT-JJ-CD-WDT-VBZ-JJ-NN-VB-JJ...\n",
       "3        NN-IN-NN-NN-VBD-VBG-PRP$-NNS-IN-NN-TO-VB-PRP$-...\n",
       "4        JJ-TO-VB-CD-PRP$-JJ-NN-CC-NN-IN-NN-MD-RB-VB-JJ...\n",
       "                               ...                        \n",
       "35550    IN-JJ-NNS-VBP-NN-IN-DT-NNS-NNS-VBP-NN-TO-VB-NN...\n",
       "35551    NNS-NNS-VBP-MD-PRP-VB-IN-DT-JJ-NN-TO-VB-DT-JJ-...\n",
       "35552    RB-IN-DT-NN-IN-JJ-NNS-NN-CC-VBG-RB-TO-VB-JJ-NN...\n",
       "35553    NNS-VBP-TO-VB-NNS-RB-IN-JJ-NN-NN-VBP-JJ-NN-CC-...\n",
       "35554    NN-CC-JJ-NNS-VBP-VBN-TO-DT-NN-IN-PRP$-NNS-CC-P...\n",
       "Name: text_pos, Length: 35555, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_tags(text):\n",
    "    # form a string of tags from POS-tag text\n",
    "    return \"-\".join(tag for (word, tag) in text)\n",
    "\n",
    "df[\"text_pos\"] = text_tagged.apply(retrieve_tags)\n",
    "df.text_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "df.to_csv(\"pos_tagged_data.csv\",index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "Associate a real-valued vector to each word in a document, so that words that occur in similar context (i.e. are semantically close) have a similar vector representation.\n",
    "\n",
    "* word2vec: compute word embeddings using the concept of context, i.e. the words around a certain word in the text. The embeddings are calculated based on the probability of each word to appear in the context of every other word (word-word co-occurrences).\n",
    "\n",
    "* Glove: unsupervised learning model trained on word-word co-occurence counts, computed with respect to the entire document as opposed to one context window at a time. Embeddings are computed based on the probability of a word to appear in the context of another word, given the entire vocabulary.\n",
    "\n",
    "Spacy offers pre-trained word embedding models (such as \"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pos_tagged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embedding model from spacy\n",
    "nlp = spacy.load('en_core_web_md') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If there's an elderly person/couple that cant make it to the grocery store or simply doesn't want to go, I'd be happy to go for you.\r",
      "\r\n",
      "\r",
      "\r\n",
      "If you know someone in need in or around Lewisville/Frisco please DM me and well try to figure this out.\r",
      "\r\n",
      "\r",
      "\r\n",
      "#coronavirus\n",
      "\n",
      "[-2.7490519e-02  2.0281416e-01 -2.2748066e-01 -1.4905868e-02\n",
      "  1.6965389e-01  1.5237168e-02  7.1119017e-04 -1.3185921e-01\n",
      "  4.9717598e-02  2.1103685e+00 -3.0328292e-01  4.3889385e-02\n",
      "  6.8924733e-02 -4.2091046e-02 -1.3894117e-01 -4.8102524e-02\n",
      " -9.9693954e-02  1.1581578e+00 -1.8420157e-01  3.2409581e-03]\n"
     ]
    }
   ],
   "source": [
    "# example on random tweet\n",
    "print( nlp(text) )\n",
    "print( )\n",
    "print( nlp(text).vector[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack embeddings of tweets\n",
    "# each tweet has a 1x300 embedding\n",
    "emb = np.vstack(df.tweet_clean.apply(lambda x: nlp(x).vector))\n",
    "len(emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35555, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.076797</td>\n",
       "      <td>0.102554</td>\n",
       "      <td>-0.236563</td>\n",
       "      <td>0.028268</td>\n",
       "      <td>0.070915</td>\n",
       "      <td>-0.061551</td>\n",
       "      <td>-0.036246</td>\n",
       "      <td>-0.174649</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>2.163169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232881</td>\n",
       "      <td>0.069883</td>\n",
       "      <td>0.037603</td>\n",
       "      <td>0.107009</td>\n",
       "      <td>0.110007</td>\n",
       "      <td>-0.039752</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>-0.083609</td>\n",
       "      <td>0.049947</td>\n",
       "      <td>0.109183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.026830</td>\n",
       "      <td>0.102297</td>\n",
       "      <td>-0.044997</td>\n",
       "      <td>-0.080606</td>\n",
       "      <td>0.064981</td>\n",
       "      <td>-0.063829</td>\n",
       "      <td>0.109534</td>\n",
       "      <td>-0.121425</td>\n",
       "      <td>0.203229</td>\n",
       "      <td>1.539385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048992</td>\n",
       "      <td>0.069090</td>\n",
       "      <td>-0.089975</td>\n",
       "      <td>0.101337</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>-0.179043</td>\n",
       "      <td>0.053799</td>\n",
       "      <td>-0.075289</td>\n",
       "      <td>-0.157458</td>\n",
       "      <td>0.210272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.056573</td>\n",
       "      <td>0.123229</td>\n",
       "      <td>-0.196744</td>\n",
       "      <td>-0.070498</td>\n",
       "      <td>0.025334</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>-0.015635</td>\n",
       "      <td>-0.112227</td>\n",
       "      <td>0.026234</td>\n",
       "      <td>1.977562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144980</td>\n",
       "      <td>0.050027</td>\n",
       "      <td>-0.064219</td>\n",
       "      <td>-0.096617</td>\n",
       "      <td>0.132238</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>-0.072627</td>\n",
       "      <td>-0.106172</td>\n",
       "      <td>0.048989</td>\n",
       "      <td>0.095878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.043067</td>\n",
       "      <td>0.247374</td>\n",
       "      <td>-0.191714</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.084943</td>\n",
       "      <td>0.140692</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>-0.172337</td>\n",
       "      <td>-0.023317</td>\n",
       "      <td>2.047875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074178</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>-0.025367</td>\n",
       "      <td>-0.024489</td>\n",
       "      <td>0.172260</td>\n",
       "      <td>-0.078927</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.047417</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>0.209466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.025101</td>\n",
       "      <td>0.178041</td>\n",
       "      <td>-0.127984</td>\n",
       "      <td>0.028439</td>\n",
       "      <td>0.155111</td>\n",
       "      <td>-0.118528</td>\n",
       "      <td>0.019113</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>0.122513</td>\n",
       "      <td>2.120510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153965</td>\n",
       "      <td>0.037664</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>-0.025716</td>\n",
       "      <td>-0.088436</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.033921</td>\n",
       "      <td>-0.054791</td>\n",
       "      <td>0.129360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.076797  0.102554 -0.236563  0.028268  0.070915 -0.061551 -0.036246   \n",
       "1 -0.026830  0.102297 -0.044997 -0.080606  0.064981 -0.063829  0.109534   \n",
       "2 -0.056573  0.123229 -0.196744 -0.070498  0.025334  0.006841 -0.015635   \n",
       "3 -0.043067  0.247374 -0.191714  0.004885  0.084943  0.140692  0.025693   \n",
       "4 -0.025101  0.178041 -0.127984  0.028439  0.155111 -0.118528  0.019113   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0 -0.174649 -0.004603  2.163169  ... -0.232881  0.069883  0.037603  0.107009   \n",
       "1 -0.121425  0.203229  1.539385  ... -0.048992  0.069090 -0.089975  0.101337   \n",
       "2 -0.112227  0.026234  1.977562  ... -0.144980  0.050027 -0.064219 -0.096617   \n",
       "3 -0.172337 -0.023317  2.047875  ... -0.074178  0.012089 -0.025367 -0.024489   \n",
       "4 -0.001518  0.122513  2.120510  ... -0.153965  0.037664  0.010684 -0.000414   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.110007 -0.039752  0.001534 -0.083609  0.049947  0.109183  \n",
       "1  0.007872 -0.179043  0.053799 -0.075289 -0.157458  0.210272  \n",
       "2  0.132238  0.013350 -0.072627 -0.106172  0.048989  0.095878  \n",
       "3  0.172260 -0.078927  0.042802  0.047417  0.043778  0.209466  \n",
       "4 -0.025716 -0.088436 -0.001956 -0.033921 -0.054791  0.129360  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert embeddings to dataframe\n",
    "emb_df = pd.DataFrame(emb, columns = np.array([str(x) for x in range(0, len(emb[0]))]) )\n",
    "print(emb_df.shape)\n",
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add embeddings to dataset\n",
    "df_embed = pd.concat([df, emb_df], axis = 1)\n",
    "df = df_embed.drop(columns=[\"OriginalTweet\",'word_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert target label to real-valued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "35550    0\n",
       "35551    0\n",
       "35552    1\n",
       "35553    0\n",
       "35554    1\n",
       "Name: target_encoded, Length: 35555, dtype: int32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sentiment label to real-valued target\n",
    "le = LabelEncoder()\n",
    "le.fit(df.Sentiment)\n",
    "\n",
    "df['target_encoded'] = le.transform(df.Sentiment)\n",
    "df.target_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "df.to_csv(\"preprocessed_data.csv\",index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with machine learning models\n",
    "\n",
    "We consider the following classifiers:\n",
    "\n",
    "* Multinomial Naive Bayes Model (benchmark)\n",
    "* Random forests\n",
    "* Adaptive boosting (ADABoost)\n",
    "* Extreme Gradient Boosting (XGBoost)\n",
    "\n",
    "The machine learning models are trained on a real-valued representation of the training data, produced with the following nlp preprocesssing methods: \n",
    "\n",
    "* Bag-of-words model\n",
    "* Bag-of-POS model\n",
    "* Pre-trained word embeddings\n",
    "\n",
    "To reduce computational time, we train the machine learning models on a random sample with dimensions equal to 30% of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35555, 304)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp = pd.read_csv(\"preprocessed_data.csv\")\n",
    "df_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10666, 304)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the models on about 30% of the original data\n",
    "df = df_imp.sample(frac = 0.3 ) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle data\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df = df.reset_index(drop=True) # reset the index after the permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8532 2134\n"
     ]
    }
   ],
   "source": [
    "# define train and test size\n",
    "train_size = int( len(df)*0.8 )\n",
    "test_size = int( len(df) - train_size )\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "df_train = df.head(train_size)\n",
    "y_train = df.head(train_size).target_encoded\n",
    "\n",
    "df_test = df.tail(test_size)\n",
    "y_test = df.tail(test_size).target_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tfidf and cross validation parameters for all models\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, \n",
    "                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive bayes model \n",
    "Probabilistic classifier with independence assumption between fetures\n",
    "\n",
    "The model is trained on the real-valued representation of the tweets produces by nltk CountVectorizer(), which transforms text into a vector of token counts.\n",
    "In the resulting sparse matrix, each column represents a unique word in the vocabulary, and each row represents a tweet in the dataset. The values of the matrix are the word counts. Words that do not appear in a certain tweet are given the value zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.tweet_clean\n",
    "X_test = df_test.tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tweets into a real-valued matrix of token counts (sparse matrix with dim nr tweets, nr words)\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "vect.fit(X_train)\n",
    "\n",
    "x_train_dtm = vect.transform(X_train)\n",
    "x_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wagsocialcare': 24999,\n",
       " 'walgreens': 25029,\n",
       " 'workers': 25618,\n",
       " 'lines': 14125,\n",
       " 'pandemic': 17289,\n",
       " 'masks': 14881,\n",
       " 'need': 16020,\n",
       " 'yesterday': 26082,\n",
       " 'pure': 18668,\n",
       " 'public': 18609,\n",
       " 'safety': 20321,\n",
       " 'hazard': 11088,\n",
       " 'pay': 17489,\n",
       " 'hand': 10951,\n",
       " 'sanitizer': 20422,\n",
       " 'station': 21994,\n",
       " 'coronavirus': 5878,\n",
       " 'special': 21723,\n",
       " 'thank': 23077,\n",
       " 'medical': 15051,\n",
       " 'sanitation': 20412,\n",
       " 'supermarket': 22474,\n",
       " 'bodega': 3675,\n",
       " 'essential': 8508,\n",
       " 'personnel': 17645,\n",
       " 'time': 23334,\n",
       " 'truly': 23783,\n",
       " 'appreciate': 2466,\n",
       " 'hard': 11010,\n",
       " 'work': 25613,\n",
       " 'dedication': 6859,\n",
       " 'difficult': 7220,\n",
       " 'times': 23343,\n",
       " 'safe': 20310,\n",
       " 'sajithpremadasa': 20345,\n",
       " 'kindly': 13431,\n",
       " 'help': 11209,\n",
       " 'required': 19629,\n",
       " 'beacuse': 3235,\n",
       " 'lost': 14382,\n",
       " 'job': 12974,\n",
       " 'covid': 6079,\n",
       " '19': 251,\n",
       " 'entire': 8400,\n",
       " 'country': 6044,\n",
       " 'lockdown': 14265,\n",
       " 'stock': 22147,\n",
       " 'food': 9554,\n",
       " 'make': 14662,\n",
       " 'small': 21420,\n",
       " 'live': 14179,\n",
       " 'escape': 8496,\n",
       " 'critical': 6328,\n",
       " 'issue': 12634,\n",
       " 'whatsapp': 25354,\n",
       " '94754284300': 1400,\n",
       " 'awkward': 2886,\n",
       " 'moment': 15487,\n",
       " 'realize': 19271,\n",
       " 'better': 3398,\n",
       " 'protection': 18527,\n",
       " 'nurses': 16487,\n",
       " 'sweeps': 22638,\n",
       " 'globe': 10386,\n",
       " 'delivery': 6946,\n",
       " 'drivers': 7733,\n",
       " 'responders': 19703,\n",
       " 'unlike': 24285,\n",
       " 'traditional': 23626,\n",
       " 'emergency': 8247,\n",
       " 'face': 8899,\n",
       " 'sick': 21179,\n",
       " 'insurance': 12399,\n",
       " 'https': 11650,\n",
       " 'upwiywdgav': 24386,\n",
       " '4oysvz4iak': 839,\n",
       " 'person': 17641,\n",
       " 'bought': 3809,\n",
       " 'flour': 9478,\n",
       " 'local': 14253,\n",
       " 'certainly': 4706,\n",
       " 'recipe': 19323,\n",
       " 'regular': 19461,\n",
       " 'delayed': 6925,\n",
       " 'covid_19': 6142,\n",
       " 'basic': 3126,\n",
       " 'easy': 7974,\n",
       " 'way': 25154,\n",
       " 'stay': 22006,\n",
       " 'occupied': 16644,\n",
       " 'fed': 9129,\n",
       " 'isolation': 12623,\n",
       " 'nab5ce9xgb': 15854,\n",
       " '2kg0odvhaa': 521,\n",
       " 'avoid': 2862,\n",
       " 'stressful': 22280,\n",
       " 'scenesâ': 20566,\n",
       " 'support': 22505,\n",
       " 'economically': 8033,\n",
       " 'vulnerable': 24932,\n",
       " 'business': 4169,\n",
       " 'ownersâ': 17168,\n",
       " 'spending': 21754,\n",
       " 'money': 15512,\n",
       " 'markets': 14829,\n",
       " 'instead': 12377,\n",
       " 'big': 3468,\n",
       " 'box': 3832,\n",
       " 'retailers': 19758,\n",
       " 'rf17kkfljt': 19842,\n",
       " 'tremendous': 23712,\n",
       " 'healthcare': 11140,\n",
       " 'grocery': 10716,\n",
       " 'store': 22216,\n",
       " 'employees': 8281,\n",
       " 'vendors': 24646,\n",
       " 'providers': 18557,\n",
       " 'pharmacy': 17713,\n",
       " 'restaurant': 19719,\n",
       " 'going': 10461,\n",
       " 'bless': 3592,\n",
       " 'order': 16956,\n",
       " 'items': 12664,\n",
       " 'online': 16864,\n",
       " 'amp': 2238,\n",
       " 'delivered': 6941,\n",
       " 'door': 7608,\n",
       " 'instructions': 12388,\n",
       " 'let': 13970,\n",
       " 'know': 13505,\n",
       " 'emailing': 8226,\n",
       " 'info': 12258,\n",
       " 'brewline': 3947,\n",
       " 'uk': 24079,\n",
       " 'working': 25626,\n",
       " 'ensure': 8384,\n",
       " 'precautions': 18222,\n",
       " 'taken': 22769,\n",
       " 'meet': 15072,\n",
       " 'process': 18397,\n",
       " 'demand': 6953,\n",
       " 'covid2019': 6133,\n",
       " 'wwfhpzj2e0': 25768,\n",
       " '5jyccxclka': 968,\n",
       " 'gold': 10465,\n",
       " 'prices': 18336,\n",
       " 'continue': 5680,\n",
       " 'soar': 21512,\n",
       " 'expectations': 8736,\n",
       " 'worst': 25667,\n",
       " 'recession': 19321,\n",
       " 'world': 25636,\n",
       " 'seen': 20745,\n",
       " 'grow': 10739,\n",
       " 'day': 6722,\n",
       " 'impact': 12032,\n",
       " 'economy': 8043,\n",
       " 'mhf1hd3zj0': 15196,\n",
       " 'rakamoto': 19115,\n",
       " 'mondaythoughts': 15505,\n",
       " 'blockchain': 3615,\n",
       " 'crypto': 6386,\n",
       " 'bitcoin': 3529,\n",
       " 'digital': 7227,\n",
       " 'watch': 25133,\n",
       " 'surgeon': 22544,\n",
       " 'general': 10175,\n",
       " 'shows': 21148,\n",
       " 'inhaler': 12291,\n",
       " 'says': 20519,\n",
       " 'feared': 9112,\n",
       " 'fatal': 9056,\n",
       " 'asthma': 2695,\n",
       " 'attack': 2738,\n",
       " 'life': 14070,\n",
       " 'explains': 8765,\n",
       " 'black': 3559,\n",
       " 'americans': 2218,\n",
       " 'greater': 10659,\n",
       " 'risk': 19932,\n",
       " 'demographics': 6968,\n",
       " '206efujqex': 402,\n",
       " 'qv4ym9fjta': 18997,\n",
       " 'people': 17587,\n",
       " 'dying': 7885,\n",
       " 'doctors': 7514,\n",
       " 'losing': 14378,\n",
       " 'mind': 15291,\n",
       " 'podium': 17979,\n",
       " 'briefing': 3967,\n",
       " 'room': 20070,\n",
       " 'white': 25392,\n",
       " 'house': 11581,\n",
       " 'use': 24432,\n",
       " 'friends': 9832,\n",
       " 'left': 13901,\n",
       " 'mailbox': 14637,\n",
       " 'knows': 13510,\n",
       " 'tuesday': 23858,\n",
       " 'week': 25242,\n",
       " 'list': 14154,\n",
       " 'today': 23424,\n",
       " 'mask': 14876,\n",
       " 'traditionally': 23627,\n",
       " 'frown': 9858,\n",
       " 'behaviour': 3311,\n",
       " 'cheaper': 4817,\n",
       " 'absynth': 1603,\n",
       " 'actual': 1719,\n",
       " 'ffs': 9212,\n",
       " 'idealworld': 11875,\n",
       " 'selling': 20790,\n",
       " '500ml': 882,\n",
       " 'near': 16001,\n",
       " '20': 369,\n",
       " 'plus': 17943,\n",
       " 'postage': 18110,\n",
       " 'changed': 4756,\n",
       " 'rules': 20192,\n",
       " 'social': 21528,\n",
       " 'distancing': 7406,\n",
       " 'didn': 7198,\n",
       " 'young': 26172,\n",
       " 'woman': 25577,\n",
       " 'told': 23467,\n",
       " 'rude': 20179,\n",
       " 'excuse': 8688,\n",
       " 'ppl': 18178,\n",
       " 'disrespectful': 7389,\n",
       " 'fucking': 9895,\n",
       " 'surprise': 22555,\n",
       " 'just': 13135,\n",
       " 'watched': 25135,\n",
       " 'parking': 17376,\n",
       " 'lot': 14384,\n",
       " 'load': 14236,\n",
       " 'car': 4456,\n",
       " 'pull': 18631,\n",
       " 'latex': 13775,\n",
       " 'gloves': 10392,\n",
       " 'throw': 23277,\n",
       " 'ground': 10732,\n",
       " 'like': 14097,\n",
       " 'er': 8461,\n",
       " 'called': 4325,\n",
       " 'tell': 22950,\n",
       " 'family': 8985,\n",
       " 'um': 24115,\n",
       " 'pick': 17761,\n",
       " 'shit': 21049,\n",
       " 'given': 10323,\n",
       " 'self': 20766,\n",
       " 'centred': 4693,\n",
       " 'aggressive': 1933,\n",
       " 'streets': 22267,\n",
       " 'aisles': 2014,\n",
       " 'australia': 2812,\n",
       " 'iâ': 12712,\n",
       " 'thrilled': 23268,\n",
       " 'weâ': 25322,\n",
       " 'war': 25072,\n",
       " 'immediate': 12014,\n",
       " 'threat': 23257,\n",
       " 'peopleâ': 17594,\n",
       " 'true': 23780,\n",
       " 'selves': 20796,\n",
       " 'emerge': 8243,\n",
       " 'stress': 22277,\n",
       " 'pressure': 18296,\n",
       " 'failing': 8940,\n",
       " 'previous': 18324,\n",
       " 'lax': 13821,\n",
       " 'standards': 21941,\n",
       " 'covid19aus': 6086,\n",
       " 'fine': 9313,\n",
       " 'folks': 9542,\n",
       " 'train': 23636,\n",
       " 'wreck': 25700,\n",
       " 'distillery': 7412,\n",
       " 'producing': 18413,\n",
       " 'outbreak': 17045,\n",
       " 'great': 10655,\n",
       " 'canâ': 4421,\n",
       " 'wait': 25006,\n",
       " 'visit': 24788,\n",
       " 'sit': 21286,\n",
       " 'smokey': 21455,\n",
       " 'comet': 5357,\n",
       " '2xozuv0djd': 574,\n",
       " 'mxjnogbsok': 15789,\n",
       " 'united': 24259,\n",
       " 'kingdom': 13437,\n",
       " 'consumer': 5624,\n",
       " 'inflation': 12247,\n",
       " 'fell': 9165,\n",
       " 'news': 16112,\n",
       " 'follow': 9544,\n",
       " 'page': 17245,\n",
       " 'forex': 9641,\n",
       " 'forexmarket': 9642,\n",
       " 'internationaldayofhappiness': 12447,\n",
       " 'coronacrisis': 5824,\n",
       " 'power': 18154,\n",
       " 'don': 7564,\n",
       " 'fear': 9111,\n",
       " 'created': 6266,\n",
       " 'mixed': 15386,\n",
       " 'trigger': 23733,\n",
       " 'cells': 4682,\n",
       " 'zaps': 26309,\n",
       " 'causing': 4599,\n",
       " 'symptoms': 22697,\n",
       " 'death': 6790,\n",
       " 'lies': 14068,\n",
       " 'lie': 14065,\n",
       " 'roe_con': 20035,\n",
       " 'annekasaba': 2330,\n",
       " 'rachelpatzerphd': 19069,\n",
       " 'yes': 26080,\n",
       " 'gratitude': 10645,\n",
       " 'staff': 21914,\n",
       " 'supply': 22495,\n",
       " 'chain': 4735,\n",
       " 'clerks': 5136,\n",
       " 'stores': 22220,\n",
       " 'irrational': 12584,\n",
       " 'mobs': 15440,\n",
       " 'leave': 13883,\n",
       " 'tp': 23581,\n",
       " 'reservations': 19649,\n",
       " 'marketplace': 14825,\n",
       " 'came': 4356,\n",
       " 'upcoming': 24353,\n",
       " 'dates': 6697,\n",
       " 'tomorrow': 23482,\n",
       " 'saturday': 20476,\n",
       " 'april': 2491,\n",
       " '4th': 856,\n",
       " 'sunday': 22441,\n",
       " '5th': 999,\n",
       " 'reserve': 19650,\n",
       " '30': 578,\n",
       " 'minute': 15329,\n",
       " 'shopping': 21097,\n",
       " 'window': 25463,\n",
       " 'cookathome': 5737,\n",
       " 'dreamkitchen': 7709,\n",
       " 'boston': 3791,\n",
       " 'xtmnpekmdj': 25953,\n",
       " 'uncertain': 24149,\n",
       " 'listen': 14156,\n",
       " 'saying': 20518,\n",
       " 'experiences': 8751,\n",
       " 'aoq7ychxyw': 2397,\n",
       " 'marketresearch': 14828,\n",
       " 'socialmedia': 21549,\n",
       " 'branding': 3887,\n",
       " 'analytics': 2270,\n",
       " '5ccc9zcgzs': 943,\n",
       " 'aoc': 2394,\n",
       " 'breaking': 3921,\n",
       " 'endorse': 8327,\n",
       " 'sen': 20805,\n",
       " 'bernie': 3377,\n",
       " 'sanders': 20398,\n",
       " 'travel': 23689,\n",
       " 'spreading': 21832,\n",
       " 'awareness': 2879,\n",
       " 'importance': 12060,\n",
       " 'm4a': 14568,\n",
       " 'inequality': 12222,\n",
       " 'paying': 17496,\n",
       " '15': 208,\n",
       " 'hour': 11575,\n",
       " 'guy': 10825,\n",
       " 'stocks': 22169,\n",
       " 'shelves': 21006,\n",
       " 'ur': 24389,\n",
       " 'latest': 13774,\n",
       " 'dairypod': 6628,\n",
       " 'caught': 4593,\n",
       " 'fresh': 9809,\n",
       " 'agenda': 1919,\n",
       " 'director': 7276,\n",
       " 'steve': 22101,\n",
       " 'spencer': 21751,\n",
       " 'look': 14338,\n",
       " 'farm': 9017,\n",
       " 'gate': 10098,\n",
       " 'milk': 15271,\n",
       " 'shaping': 20959,\n",
       " 'post': 18109,\n",
       " 'soundcloud': 21644,\n",
       " 'subscribe': 22359,\n",
       " 'apple': 2445,\n",
       " 'podcasts': 17977,\n",
       " 'google': 10497,\n",
       " 'play': 17892,\n",
       " 'dime': 7243,\n",
       " 'algo': 2080,\n",
       " 'publixhelps': 18623,\n",
       " 'publix': 18622,\n",
       " 'advocating': 1842,\n",
       " 'senior': 20824,\n",
       " 'hours': 11578,\n",
       " 'happen': 10993,\n",
       " 'miami': 15206,\n",
       " 'manufacturers': 14757,\n",
       " 'wisconsin': 25505,\n",
       " 'making': 14673,\n",
       " 'products': 18419,\n",
       " 'toilet': 23439,\n",
       " 'paper': 17329,\n",
       " 'canned': 4407,\n",
       " 'ramp': 19135,\n",
       " 'consumers': 5635,\n",
       " 'planning': 17874,\n",
       " 'impacts': 12037,\n",
       " 'workforce': 25622,\n",
       " 'virus': 24775,\n",
       " 'spreads': 21834,\n",
       " 'reports': 19606,\n",
       " 'hopekirwan': 11525,\n",
       " 'meganmariehart': 15080,\n",
       " 'wpr': 25685,\n",
       " 'zpemi0lr5z': 26422,\n",
       " 'shoutout': 21137,\n",
       " 'blairkaylor': 3571,\n",
       " 'tirelessly': 23370,\n",
       " 'crisis': 6319,\n",
       " 'farmers': 9021,\n",
       " 'wouldnâ': 25675,\n",
       " 'goods': 10490,\n",
       " 'produce': 18409,\n",
       " 'vital': 24803,\n",
       " 'rhubarb': 19860,\n",
       " 'early': 7942,\n",
       " 'spring': 21839,\n",
       " 'cabbages': 4282,\n",
       " 'mention': 15121,\n",
       " 'tea': 22881,\n",
       " 'tonight': 23491,\n",
       " 'leek': 13900,\n",
       " 'potato': 18133,\n",
       " 'soup': 21647,\n",
       " 'hero': 11256,\n",
       " 'marvel': 14866,\n",
       " 'good': 10480,\n",
       " 'article': 2590,\n",
       " 'diy': 7455,\n",
       " 'microscope': 15227,\n",
       " 'pictures': 17781,\n",
       " 'different': 7216,\n",
       " 'fibers': 9233,\n",
       " 'protective': 18530,\n",
       " 'abilities': 1580,\n",
       " 'covid19': 6082,\n",
       " 'coronakrise': 5843,\n",
       " 'stayhomesavelives': 22035,\n",
       " 'fridayfeeling': 9818,\n",
       " 'qh2d1gehq3': 18823,\n",
       " 'donttouchface': 7597,\n",
       " 'fentanyl': 9176,\n",
       " 'absorb': 1598,\n",
       " 'transdermally': 23653,\n",
       " 'skin': 21324,\n",
       " 'false': 8972,\n",
       " 'narrative': 15912,\n",
       " 'notwithstanding': 16394,\n",
       " 'wearing': 25210,\n",
       " 'isnâ': 12618,\n",
       " 'bad': 2989,\n",
       " 'idea': 11872,\n",
       " 'remember': 19535,\n",
       " 'touch': 23543,\n",
       " 'avg': 2856,\n",
       " '368': 635,\n",
       " 'wtfentanyl': 25733,\n",
       " 'ea1wrfjunz': 7933,\n",
       " 'airlines': 2003,\n",
       " 'verge': 24662,\n",
       " 'bankruptcy': 3067,\n",
       " 'years': 26049,\n",
       " 'scamming': 20541,\n",
       " 'extra': 8823,\n",
       " 'seats': 20710,\n",
       " 'insulting': 12397,\n",
       " 'inflight': 12251,\n",
       " 'service': 20869,\n",
       " 'fees': 9156,\n",
       " 'record': 19346,\n",
       " 'low': 14417,\n",
       " 'oil': 16746,\n",
       " 'tax': 22837,\n",
       " 'breaks': 3926,\n",
       " 'route': 20105,\n",
       " 'consolidations': 5604,\n",
       " 'em': 8221,\n",
       " 'bailout': 3010,\n",
       " 'chance': 4751,\n",
       " 'force': 9616,\n",
       " 'behave': 3305,\n",
       " 'deserved': 7052,\n",
       " 'restrict': 19733,\n",
       " 'orders': 16960,\n",
       " '70': 1147,\n",
       " '92': 1389,\n",
       " 'yo': 26148,\n",
       " 'dad': 6606,\n",
       " '300': 579,\n",
       " 'miles': 15265,\n",
       " 'away': 2880,\n",
       " '140': 200,\n",
       " 'basket': 3131,\n",
       " 'slots': 21400,\n",
       " 'supposed': 22522,\n",
       " 'cope': 5767,\n",
       " 'gel': 10166,\n",
       " 'antibacterial': 2364,\n",
       " 'wipes': 25495,\n",
       " 'shops': 21107,\n",
       " 'trying': 23828,\n",
       " 'utmost': 24484,\n",
       " 'fair': 8943,\n",
       " 'dozen': 7663,\n",
       " 'instances': 12371,\n",
       " 've': 24621,\n",
       " 'minutes': 15330,\n",
       " 'impossible': 12072,\n",
       " 'coronavirusuk': 5947,\n",
       " 'experts': 8756,\n",
       " 'panic': 17303,\n",
       " 'plenty': 17920,\n",
       " 'qldo0chdge': 18856,\n",
       " 'lsjnews': 14459,\n",
       " 'wondering': 25584,\n",
       " 'lovely': 14404,\n",
       " 'able': 1583,\n",
       " 'donate': 7571,\n",
       " '600': 1020,\n",
       " 'easter': 7963,\n",
       " 'eggs': 8122,\n",
       " 'providing': 18559,\n",
       " 'frontline': 9851,\n",
       " 'nhs': 16179,\n",
       " 'services': 20871,\n",
       " 'fighting': 9253,\n",
       " 'tesco': 23017,\n",
       " 'sainsburys': 20339,\n",
       " 'asda': 2611,\n",
       " 'aldiuk': 2066,\n",
       " 'morrisons': 15579,\n",
       " 'nhscovidheroes': 16180,\n",
       " 'countries': 6043,\n",
       " 'weathering': 25216,\n",
       " 'ways': 25155,\n",
       " 'sloat': 21397,\n",
       " 'compiled': 5451,\n",
       " 'anecdotes': 2295,\n",
       " 'press': 18291,\n",
       " 'clips': 5170,\n",
       " 'twitter': 23931,\n",
       " 'videos': 24729,\n",
       " '68': 1057,\n",
       " 'provide': 18554,\n",
       " 'snapshot': 21476,\n",
       " 'cut': 6502,\n",
       " 'roll': 20046,\n",
       " 'pack': 17224,\n",
       " 'rolled': 20048,\n",
       " 'crowd': 6356,\n",
       " 'shoppers': 21095,\n",
       " 'yelled': 26061,\n",
       " 'joke': 13016,\n",
       " 'horror': 11546,\n",
       " 'coronaviruspandemic': 5930,\n",
       " 'wuhancoronavirus': 25752,\n",
       " 'bold': 3701,\n",
       " 'decision': 6829,\n",
       " 'ban': 3038,\n",
       " 'bowel': 3826,\n",
       " 'movements': 15631,\n",
       " 'drip': 7728,\n",
       " 'dry': 7772,\n",
       " 'allowed': 2132,\n",
       " 'coronaviruslockdown': 5913,\n",
       " 'toiletpaper': 23441,\n",
       " 'rachbarnhart': 19067,\n",
       " 'rachel': 19068,\n",
       " 'california': 4319,\n",
       " 'got': 10517,\n",
       " 'gone': 10476,\n",
       " 'miss': 15354,\n",
       " 'wegmans': 25251,\n",
       " 'everyday': 8613,\n",
       " 'believe': 3332,\n",
       " 'treated': 23704,\n",
       " 'wrong': 25717,\n",
       " 'known': 13508,\n",
       " 'coast': 5246,\n",
       " 'kyliejenner': 13653,\n",
       " 'generous': 10189,\n",
       " 'donation': 7575,\n",
       " 'west': 25305,\n",
       " 'hills': 11328,\n",
       " 'hospital': 11548,\n",
       " 'greatly': 10665,\n",
       " 'fight': 9245,\n",
       " 'phase': 17716,\n",
       " 'relief': 19513,\n",
       " 'vote': 24880,\n",
       " 'supportnurses': 22515,\n",
       " 'tru': 23770,\n",
       " 'petrol': 17678,\n",
       " 'diesel': 7207,\n",
       " 'set': 20877,\n",
       " 'opec': 16898,\n",
       " 'member': 15098,\n",
       " 'states': 21987,\n",
       " 'saudi': 20487,\n",
       " 'arabia': 2510,\n",
       " 'russia': 20215,\n",
       " 'finally': 9290,\n",
       " 'reach': 19234,\n",
       " 'deal': 6777,\n",
       " 'global': 10370,\n",
       " 'crude': 6367,\n",
       " 'production': 18416,\n",
       " '10': 121,\n",
       " 'million': 15280,\n",
       " 'barrels': 3105,\n",
       " 'ramifications': 19134,\n",
       " 'india': 12160,\n",
       " 'emerging': 8253,\n",
       " 'wounds': 25677,\n",
       " 'immense': 12016,\n",
       " 'fools': 9600,\n",
       " 'think': 23210,\n",
       " 'bottled': 3803,\n",
       " 'water': 25138,\n",
       " 'huge': 11666,\n",
       " 'priority': 18367,\n",
       " 'right': 19903,\n",
       " 'gonna': 10479,\n",
       " 'filling': 9273,\n",
       " 'tap': 22806,\n",
       " 'silly': 21221,\n",
       " 'cause': 4594,\n",
       " 'desperation': 7074,\n",
       " 'im': 11994,\n",
       " 'sure': 22535,\n",
       " 'did': 7196,\n",
       " '2lz5qfvun2': 527,\n",
       " 'feeling': 9151,\n",
       " 'someoneâ': 21604,\n",
       " 'standing': 21943,\n",
       " 'close': 5175,\n",
       " 'socialdistancing': 21535,\n",
       " 'flattenthecurve': 9420,\n",
       " 's5wdgfbmy4': 20277,\n",
       " 'chop': 4958,\n",
       " 'presses': 18295,\n",
       " 'crip': 6315,\n",
       " 'pop': 18048,\n",
       " 'smoke': 21452,\n",
       " 'arrested': 2572,\n",
       " 'wf10iakpxu': 25323,\n",
       " 'rap': 19167,\n",
       " 'hiphop': 11344,\n",
       " 'viral': 24761,\n",
       " 'trending': 23715,\n",
       " 'worldstar': 25648,\n",
       " 'chicago': 4882,\n",
       " 'chiraq': 4932,\n",
       " 'atlanta': 2722,\n",
       " 'newyork': 16140,\n",
       " 'drake': 7686,\n",
       " 'trav': 23688,\n",
       " '50cent': 888,\n",
       " 'queenzflip': 18955,\n",
       " 'chrislines01': 4977,\n",
       " 'peter_fitz': 17662,\n",
       " 'newscomauhq': 16122,\n",
       " 'haven': 11074,\n",
       " 'grocer': 10712,\n",
       " 'lately': 13771,\n",
       " 'started': 21964,\n",
       " 'clinics': 5165,\n",
       " 'claiming': 5070,\n",
       " 'overwhelmed': 17140,\n",
       " 'starting': 21966,\n",
       " 'run': 20200,\n",
       " 'short': 21114,\n",
       " 'supplies': 22492,\n",
       " 'trader': 23618,\n",
       " 'joeâ': 12989,\n",
       " 'worker': 25617,\n",
       " 'scarsdale': 20558,\n",
       " 'greeter': 10687,\n",
       " 'giant': 10279,\n",
       " 'largo': 13761,\n",
       " 'md': 14997,\n",
       " 'walmart': 25046,\n",
       " 'area': 2524,\n",
       " 'died': 7203,\n",
       " 'izj5iyc7ih': 12710,\n",
       " 'wore': 25612,\n",
       " 'town': 23569,\n",
       " 'glad': 10344,\n",
       " 'kids': 13398,\n",
       " 'adults': 1805,\n",
       " 'smile': 21444,\n",
       " 'itâ': 12675,\n",
       " 'ideal': 11873,\n",
       " 'jiu1m4k8n1': 12937,\n",
       " 'getting': 10247,\n",
       " 'creative': 6270,\n",
       " 'including': 12127,\n",
       " 'things': 23208,\n",
       " 'isles': 12613,\n",
       " 'wagnruedgu': 24998,\n",
       " 'instore': 12384,\n",
       " 'retail': 19753,\n",
       " 'stop': 22184,\n",
       " 'buying': 4207,\n",
       " 'really': 19276,\n",
       " 'ialq3rsdtd': 11820,\n",
       " 'sozpi5uxoy': 21679,\n",
       " 'restaurants': 19722,\n",
       " 'cafes': 4295,\n",
       " 'deliver': 6940,\n",
       " 'offer': 16689,\n",
       " 'takeaway': 22766,\n",
       " 'tough': 23549,\n",
       " 'gas': 10092,\n",
       " 'industry': 12212,\n",
       " 'seige': 20757,\n",
       " 'having': 11079,\n",
       " 'best': 3389,\n",
       " 'recorded': 19347,\n",
       " 'history': 11358,\n",
       " 'soon': 21617,\n",
       " 'starts': 21969,\n",
       " 'does': 7527,\n",
       " 'national': 15927,\n",
       " 'security': 20730,\n",
       " 'mv4uuj1hgu': 15781,\n",
       " 'boring': 3774,\n",
       " 'lol': 14317,\n",
       " 'foodbankaus': 9559,\n",
       " 'ceo': 4699,\n",
       " 'briannacasey1': 3956,\n",
       " 'joins': 13012,\n",
       " 'unitingcare_aus': 24265,\n",
       " 'mowaustralia': 15640,\n",
       " 'chat': 4800,\n",
       " 'increasing': 12143,\n",
       " 'australian': 2814,\n",
       " 'charities': 4782,\n",
       " 'unprecedented': 24302,\n",
       " 'link': 14133,\n",
       " 'ro9mmfyptn': 19988,\n",
       " 'welp': 25287,\n",
       " 'guess': 10792,\n",
       " 'lululemon': 14486,\n",
       " 'fitting': 9374,\n",
       " 'foreseeable': 9636,\n",
       " 'future': 9961,\n",
       " 'thanks': 23083,\n",
       " 'luckily': 14475,\n",
       " 'thing': 23207,\n",
       " 'aclmbgyhzr': 1688,\n",
       " 'fda': 9101,\n",
       " 'stakeholder': 21927,\n",
       " 'shortage': 21115,\n",
       " 'animal': 2317,\n",
       " 'pet': 17656,\n",
       " 'related': 19486,\n",
       " 'ingredients': 12287,\n",
       " 'wide': 25424,\n",
       " 'spread': 21829,\n",
       " 'disruptions': 7394,\n",
       " 'reported': 19601,\n",
       " 'delays': 6927,\n",
       " 'ordering': 16958,\n",
       " 'result': 19742,\n",
       " 'e9shyvozwo': 7929,\n",
       " 'fug4v5eiai': 9909,\n",
       " 'note': 16364,\n",
       " 'hints': 11341,\n",
       " 'secure': 20726,\n",
       " 'transactions': 23652,\n",
       " 'onlineshopping': 16871,\n",
       " 'stayhome': 22024,\n",
       " 'maltagov': 14702,\n",
       " 'robertabela_mt': 20007,\n",
       " 'financemalta': 9292,\n",
       " 'mfsacomm': 15187,\n",
       " 'mp4esaoaxu': 15645,\n",
       " 'frighteningâ': 9838,\n",
       " 'calls': 4336,\n",
       " 'government': 10538,\n",
       " 'louder': 14391,\n",
       " 'oilpatch': 16754,\n",
       " 'faces': 8907,\n",
       " 'bleak': 3589,\n",
       " 'outlook': 17062,\n",
       " 'bkqeykpsqv': 3555,\n",
       " 'figure': 9255,\n",
       " 'pops': 18053,\n",
       " 'ready': 19252,\n",
       " 'headed': 11124,\n",
       " '2020': 393,\n",
       " 'distribution': 7428,\n",
       " 'surgical': 22548,\n",
       " 'n95': 15845,\n",
       " 'sale': 20354,\n",
       " 'sanitizers': 20424,\n",
       " 'liquid': 14142,\n",
       " 'soap': 21509,\n",
       " 'available': 2846,\n",
       " 'large': 13756,\n",
       " 'reasonable': 19285,\n",
       " 'helpline': 11218,\n",
       " 'provided': 18555,\n",
       " 'atâ': 2776,\n",
       " 'gwjcjhhykq': 10837,\n",
       " 'yxdulrsrlp': 26261,\n",
       " 'sad': 20306,\n",
       " 'new': 16091,\n",
       " 'normal': 16332,\n",
       " 'didnâ': 7201,\n",
       " 'youâ': 26194,\n",
       " 'banks': 3068,\n",
       " 'panicbuying': 17307,\n",
       " 'requested': 19625,\n",
       " 'video': 24725,\n",
       " 'followed': 9545,\n",
       " 'excellent': 8666,\n",
       " 'guidelines': 10799,\n",
       " 'manufacture': 14754,\n",
       " 'scrub': 20660,\n",
       " 'retweets': 19799,\n",
       " 'appreciated': 2467,\n",
       " 'amazing': 2185,\n",
       " 'lowest': 14425,\n",
       " 'offers': 16693,\n",
       " 'barwa': 3117,\n",
       " 'old': 16797,\n",
       " 'airport': 2005,\n",
       " 'al': 2035,\n",
       " 'khor': 13381,\n",
       " 'branch': 3881,\n",
       " 'open': 16899,\n",
       " '24': 449,\n",
       " 'pdf': 17525,\n",
       " 'd0loth2miv': 6561,\n",
       " 'ansar': 2351,\n",
       " 'ansargallery': 2352,\n",
       " 'deals': 6783,\n",
       " 'qatar': 18779,\n",
       " 'doha': 7537,\n",
       " 'corona': 5811,\n",
       " 'hihjvfmkru': 11314,\n",
       " 'bath': 3141,\n",
       " 'body': 3681,\n",
       " 'works': 25632,\n",
       " 'smell': 21438,\n",
       " 'unicorn': 24236,\n",
       " 'fart': 9035,\n",
       " 'staysafe': 22052,\n",
       " 'coronavirusmemes': 5917,\n",
       " 'thanos': 23099,\n",
       " 'avengers': 2851,\n",
       " 'funnymemes': 9942,\n",
       " 'sarcasm': 20456,\n",
       " 'dank': 6664,\n",
       " 'dankmemes': 6666,\n",
       " 'tuesdathoughts': 23857,\n",
       " '2zikuyldfd': 577,\n",
       " 'agrees': 1947,\n",
       " 'measures': 15027,\n",
       " '9mttgxamjf': 1461,\n",
       " 'usdawunion': 24427,\n",
       " 'supermarkets': 22477,\n",
       " 'hazemat': 11091,\n",
       " 'suits': 22423,\n",
       " 'protect': 18522,\n",
       " 'postal': 18111,\n",
       " 'citizens': 5036,\n",
       " 'america': 2214,\n",
       " 'fullmoon': 9915,\n",
       " 'shutitdown': 21163,\n",
       " 'definitely': 6901,\n",
       " 'ramped': 19137,\n",
       " 'said': 20335,\n",
       " 'wasn': 25122,\n",
       " 'billionaires': 3488,\n",
       " 'politicians': 18012,\n",
       " 'saved': 20500,\n",
       " 'janitors': 12806,\n",
       " 'bin': 3497,\n",
       " 'men': 15109,\n",
       " 'paramedics': 17352,\n",
       " 'police': 17997,\n",
       " 'texas': 23040,\n",
       " 'alcoholic': 2061,\n",
       " 'beverages': 3409,\n",
       " 'purchases': 18666,\n",
       " 'customers': 6496,\n",
       " 'response': 19708,\n",
       " 'waived': 25016,\n",
       " 'regulations': 19468,\n",
       " 'hindered': 11334,\n",
       " 'weeks': 25247,\n",
       " 'important': 12061,\n",
       " 'theyâ': 23202,\n",
       " 'source': 21652,\n",
       " 'texans': 23038,\n",
       " 'j9lfsdfcee': 12737,\n",
       " 'position': 18090,\n",
       " 'want': 25064,\n",
       " 'consider': 5586,\n",
       " 'donating': 7574,\n",
       " 'bank': 3057,\n",
       " 'families': 8982,\n",
       " 'individuals': 12198,\n",
       " 'arenâ': 2529,\n",
       " 'programs': 18450,\n",
       " 'rely': 19522,\n",
       " 'running': 20204,\n",
       " 'q0itrtrv0z': 18742,\n",
       " 'foodbank': 9558,\n",
       " 'went': 25295,\n",
       " 'cookies': 5741,\n",
       " 'needed': 16021,\n",
       " 'wine': 25468,\n",
       " 'spirits': 21777,\n",
       " 'home': 11464,\n",
       " 'hunker': 11699,\n",
       " 'calmlyshopping': 4343,\n",
       " 'age': 1915,\n",
       " 'non': 16306,\n",
       " 'existent': 8713,\n",
       " 'income': 12128,\n",
       " 'currently': 6475,\n",
       " 'supporting': 22509,\n",
       " 'needs': 16025,\n",
       " 'selfisolating': 20777,\n",
       " 'tvs': 23906,\n",
       " 'electronics': 8191,\n",
       " 'health': 11138,\n",
       " 'husband': 11720,\n",
       " 'colleagues': 5307,\n",
       " 'multinational': 15732,\n",
       " 'employer': 8283,\n",
       " 'refuses': 19435,\n",
       " 'doors': 7612,\n",
       " 'expects': 8740,\n",
       " 'final': 9286,\n",
       " 'attempt': 2743,\n",
       " 'die': 7202,\n",
       " 'possible': 18107,\n",
       " 'lots': 14388,\n",
       " 'pubs': 18624,\n",
       " 'party': 17410,\n",
       " 'free': 9778,\n",
       " 'pool': 18036,\n",
       " 'jukebox': 13113,\n",
       " 'thanet': 23076,\n",
       " 'pubclosures': 18606,\n",
       " 'shutdownuk': 21162,\n",
       " 'borisjohnson': 3777,\n",
       " 'angrybritain': 2309,\n",
       " 'fuckingidiots': 9897,\n",
       " 'todayâ': 23428,\n",
       " 'episode': 8439,\n",
       " 'whatâ': 25360,\n",
       " '45': 764,\n",
       " 'mental': 15116,\n",
       " 'check': 4824,\n",
       " 'tested': 23027,\n",
       " 'positive': 18094,\n",
       " 'discovered': 7323,\n",
       " 'theyre': 23201,\n",
       " 'actually': 1720,\n",
       " 'upset': 24377,\n",
       " 'impression': 12077,\n",
       " 'std': 22062,\n",
       " 'hm': 11387,\n",
       " 'okay': 16782,\n",
       " 'obskug1fu2': 16624,\n",
       " 'socially': 21548,\n",
       " 'acceptable': 1631,\n",
       " 'ask': 2634,\n",
       " 'step': 22089,\n",
       " 'queue': 18962,\n",
       " 'trolley': 23755,\n",
       " '2m': 528,\n",
       " 'long': 14330,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training data: (8532, 26483)\n",
      "Shape test data:(2134, 26483)\n"
     ]
    }
   ],
   "source": [
    "# nrows = nr tweets, ncols = nr words\n",
    "print(\"Shape training data: {}\".format(x_train_dtm.shape) + \"\\nShape test data:{}\".format(x_test_dtm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NaiveBayes.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train_dtm, y_train)\n",
    "# save fitted model\n",
    "joblib.dump(model, \"NaiveBayes\" + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict target label (0 or 1) \n",
    "y_pred = model.predict(x_test_dtm)\n",
    "\n",
    "# predict probability of class == 1\n",
    "y_pred_prob = model.predict_proba(x_test_dtm)\n",
    "\n",
    "# performance metrics\n",
    "auc_res = list()\n",
    "acc = list()\n",
    "\n",
    "auc_res.append( roc_auc_score(y_test, y_pred_prob[:, 1]) )\n",
    "acc.append( accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------\n",
    "Random forests are an ensemble learning method for classification and regression that operates by constructing a multitude of decision trees at training time. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "The training algorithm for random forests applies the general technique of bootstrap aggregating, or bagging, to tree learners. Given a training set $X = x_1, ..., x_n$ with responses $Y = y_1, ..., y_n$, bagging repeatedly ($B$ times) selects a random sample with replacement of the training set and fits trees to these samples:\n",
    "\n",
    "For $b = 1, ..., B$:\n",
    "* Sample, with replacement, $n$ training examples from $X, Y$; call these $X_b, Y_b$.\n",
    "* Train a classification or regression tree $f_b$ on $X_b, Y_b$.\n",
    "\n",
    "After training, predictions for unseen samples can be made by averaging the predictions from all the individual regression trees on or by taking the majority vote in the case of classification trees.\n",
    "\n",
    "This bootstrapping procedure leads to better model performance because it decreases the variance of the model, without increasing the bias. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees; bootstrap sampling is a way of de-correlating the trees by showing them different training sets.\n",
    "\n",
    "Random forests also include another type of bagging scheme: they use a modified tree learning algorithm that selects, at each candidate split in the learning process, a random subset of the features. This process is sometimes called \"feature bagging\". The reason for doing this is the correlation of the trees in an ordinary bootstrap sample: if one or a few features are very strong predictors for the response variable, these features will be selected in many of the $B trees, causing them to become correlated.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "**For bag-of models**, NLP preprocessing is performed by sklearn TfidfVectorizer(), which implements lowercasing, tokenization and stopword removal and produces a \"document-term matrix\" with tf-idf normalization via the .fit transform() method. \n",
    "\n",
    "Input of TfidfVectorizer(): \n",
    "* Bag-of-words: clean tweets\n",
    "* Bag-of-POS: strings of POS tags\n",
    "\n",
    "**For pretrained word embeddings**, NLP preprocessing is not necessary and the model is trained directly on the word embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation parameters\n",
    "cv = StratifiedKFold(n_splits=5, \n",
    "                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.tweet_clean\n",
    "X_test = df_test.tweet_clean\n",
    "model_name = \"randomforest_BOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', tfidf),\n",
    "                     ('clf', RandomForestClassifier())]) # use default base learner (decision trees)\n",
    "\n",
    "param_grid = {'vect__ngram_range': [(1, 1)],    \n",
    "              'vect__stop_words': [stopwords, None],\n",
    "              'vect__max_df': [1.0, 0.1, 0.3, 0.5],\n",
    "              'vect__max_features': [None, 1000],                                           \n",
    "              'clf__n_estimators': [100, 200, 300, 400], # number of trees trained in the ensamble\n",
    "              'clf__max_depth': [1, 5, 10] # tree depth\n",
    "              }\n",
    "\n",
    "model = GridSearchCV(pipeline, \n",
    "                     param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs = -1, \n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomforest_BOW.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__max_depth': 10, 'clf__n_estimators': 400, 'vect__max_df': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 1), 'vect__stop_words': None} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.text_pos\n",
    "X_test = df_test.text_pos\n",
    "model_name = \"randomforest_POS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'vect__ngram_range': [(1, 1)],            \n",
    "              'clf__n_estimators': [100, 200, 300, 400],\n",
    "              'clf__max_depth': [1, 5, 10]}\n",
    "\n",
    "model = GridSearchCV(pipeline, \n",
    "                     param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs = -1, \n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   43.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomforest_POS.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__max_depth': 10, 'clf__n_estimators': 300, 'vect__ngram_range': (1, 1)} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns corresponding to embeddings\n",
    "select = [i for i in list(df.columns) if i not in [\"Sentiment\", \"tweet_clean\", \"text_pos\", \"target_encoded\"]]\n",
    "\n",
    "X_train = df_train[select]\n",
    "X_test = df_test[select]\n",
    "model_name = \"randomforest_EMB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('clf', RandomForestClassifier())])\n",
    "\n",
    "param_grid = {'clf__n_estimators': [100, 200, 300, 400],\n",
    "              'clf__max_depth': [1, 5, 10]}\n",
    "\n",
    "model = GridSearchCV(pipe, param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs=-1, \n",
    "                     verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['randomforest_EMB.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__max_depth': 10, 'clf__n_estimators': 400} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting algorithms consist of iteratively training weak classifiers with respect to a distribution and adding them to a final strong classifier. When they are added, they are weighted in a way that is related to the weak learners' accuracy. After a weak learner is added, the data weights are readjusted, known as \"re-weighting\". Misclassified input data gain a higher weight and examples that are classified correctly lose weight. Thus, future weak learners focus more on the examples that previous weak learners misclassified.\n",
    "\n",
    "The main variation between many boosting algorithms is their method of weighting training data points and hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.tweet_clean\n",
    "X_test = df_test.tweet_clean\n",
    "model_name = \"ADA_BOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=5) # use decision tree with max depth 5 as base learners\n",
    "\n",
    "pipeline = Pipeline([('vect', tfidf),\n",
    "                     ('clf', AdaBoostClassifier(base_estimator = tree))]) # use default base learner (decision trees)\n",
    "\n",
    "param_grid = {'vect__ngram_range': [(1, 1)],    \n",
    "              'vect__stop_words': [stopwords, None],\n",
    "              'vect__max_df': [1.0, 0.1, 0.3, 0.5],\n",
    "              'vect__max_features': [None, 1000],                                           \n",
    "              'clf__n_estimators': [100, 200, 300, 400], # number of trees trained in the ensamble\n",
    "              'clf__learning_rate': [0.001, 0.01, 0.1, 1.0]\n",
    "              }\n",
    "\n",
    "model = GridSearchCV(pipeline, \n",
    "                     param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs = -1, \n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 107.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1280 out of 1280 | elapsed: 113.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ADA_BOW.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__learning_rate': 0.1, 'clf__n_estimators': 200, 'vect__max_df': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 1), 'vect__stop_words': ['between', 'or', 'below', 'here', 'through', 'her', \"hasn't\", \"shan't\", 'our', 'its', 'mightn', \"you're\", \"aren't\", 'why', 'out', 'can', 'we', 'shouldn', 'such', 'your', 'as', 'nor', 'weren', 'from', 'herself', 'for', 'up', 'so', 'very', 'by', 'him', 'how', 'same', 'whom', 'did', 'it', 'about', 'having', 'themselves', \"won't\", 'they', 'while', 'll', 'after', 'other', \"didn't\", 'be', \"mightn't\", \"doesn't\", \"should've\", 'had', \"she's\", 'some', 'again', 'who', \"hadn't\", 'aren', 'those', 'than', 'if', 'being', 'does', 'which', \"wasn't\", 'y', 'won', 'don', 'theirs', \"you'll\", 'is', 'his', 'was', \"don't\", 'ma', 'off', 'me', 'd', 'too', \"that'll\", 'didn', 'until', 'i', 'few', 'himself', 'were', 'not', 's', 'under', \"isn't\", 'against', 'then', 'been', 'm', 'couldn', \"you've\", 'at', 'yours', 'will', 'there', 're', 'wasn', 'mustn', \"you'd\", 'down', 't', 'all', 'needn', 'because', 'over', 'o', 've', \"weren't\", \"wouldn't\", 'yourselves', 'hers', 'just', 'myself', 'my', 'haven', 'in', 'ain', 'shan', 'doesn', 'and', 'am', 'isn', 'itself', \"mustn't\", 'an', 'their', 'this', 'to', 'above', 'should', 'are', 'with', 'once', 'of', \"haven't\", 'wouldn', 'a', 'hadn', \"needn't\", \"it's\", 'on', 'them', 'these', 'when', 'ourselves', 'no', 'she', \"couldn't\", 'ours', 'further', 'during', 'where', 'both', 'only', 'what', 'he', 'has', 'most', 'that', 'but', 'before', 'into', 'the', 'own', 'hasn', 'yourself', 'each', 'have', \"shouldn't\", 'you', 'do', 'doing', 'any', 'more', 'now']} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.text_pos\n",
    "X_test = df_test.text_pos\n",
    "model_name = \"ADA_POS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'vect__ngram_range': [(1, 1)],            \n",
    "              'clf__n_estimators': [100, 200, 300, 400],\n",
    "              'clf__learning_rate': [0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "model = GridSearchCV(pipeline, \n",
    "                     param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs = -1, \n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ADA_POS.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__learning_rate': 0.001, 'clf__n_estimators': 400, 'vect__ngram_range': (1, 1)} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns corresponding to embeddings\n",
    "select = [i for i in list(df.columns) if i not in [\"Sentiment\", \"tweet_clean\", \"text_pos\", \"target_encoded\"]]\n",
    "\n",
    "X_train = df_train[select]\n",
    "X_test = df_test[select]\n",
    "model_name = \"ADA_EMB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('clf', AdaBoostClassifier(base_estimator=tree))])\n",
    "\n",
    "param_grid = {'clf__n_estimators': [100, 200, 300, 400],\n",
    "              'clf__learning_rate': [0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "model = GridSearchCV(pipe, param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs=-1, \n",
    "                     verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 92.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ADA_EMB.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__learning_rate': 0.01, 'clf__n_estimators': 400} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.tweet_clean\n",
    "X_test = df_test.tweet_clean\n",
    "model_name = \"XGB_BOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', tfidf),\n",
    "                     ('clf', XGBClassifier())]) # use default base learner (decision trees)\n",
    "\n",
    "param_grid = {'vect__ngram_range': [(1, 1)],    \n",
    "              'vect__stop_words': [stopwords, None],\n",
    "              'vect__max_df': [1.0, 0.1, 0.3, 0.5],\n",
    "              'vect__max_features': [None, 1000],                                           \n",
    "              'clf__n_estimators': [100, 200, 300, 400], # number of trees trained in the ensamble\n",
    "              'clf__learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "              'clf__max_depth': [1, 5, 10] # tree depth\n",
    "              }\n",
    "\n",
    "model = GridSearchCV(pipeline, \n",
    "                     param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs = -1, \n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 75.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 116.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 157.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 215.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed: 265.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:47:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGB_BOW.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__learning_rate': 0.1, 'clf__max_depth': 10, 'clf__n_estimators': 400, 'vect__max_df': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 1), 'vect__stop_words': None} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.text_pos\n",
    "X_test = df_test.text_pos\n",
    "model_name = \"XGB_POS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'vect__ngram_range': [(1, 1)],            \n",
    "              'clf__n_estimators': [100, 200, 300, 400],\n",
    "              'clf__learning_rate': [0.001, 0.01, 0.1, 1.0], \n",
    "              'clf__max_depth': [1, 5, 10]}\n",
    "\n",
    "model = GridSearchCV(pipeline, \n",
    "                     param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs = -1, \n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 13.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:36:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGB_POS.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__learning_rate': 0.1, 'clf__max_depth': 1, 'clf__n_estimators': 300, 'vect__ngram_range': (1, 1)} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns corresponding to embeddings\n",
    "select = [i for i in list(df.columns) if i not in [\"Sentiment\", \"tweet_clean\", \"text_pos\", \"target_encoded\"]]\n",
    "\n",
    "X_train = df_train[select]\n",
    "X_test = df_test[select]\n",
    "model_name = \"XGB_EMB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('clf', XGBClassifier())])\n",
    "\n",
    "param_grid = {'clf__n_estimators': [100, 200, 300, 400],\n",
    "              'clf__learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "              'clf__max_depth': [1, 5, 10]}\n",
    "\n",
    "model = GridSearchCV(pipe, param_grid,\n",
    "                     scoring='roc_auc',\n",
    "                     cv=cv, \n",
    "                     n_jobs=-1, \n",
    "                     verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 94.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 111.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGB_EMB.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# save fitted model\n",
    "joblib.dump(model, model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fitted model\n",
    "model = joblib.load(model_name + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 400} \n"
     ]
    }
   ],
   "source": [
    "params, auc, accuracy = test_performance(model, X_test)\n",
    "\n",
    "auc_res.append( auc )\n",
    "acc.append( accuracy )\n",
    "\n",
    "print('Best parameter set: %s ' % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models\n",
    "\n",
    "* $Accuracy = \\frac{TP + TN}{TP+ TN + FP + FN}$\n",
    "* AUC ROC (Area Under the Receiver Operating Characteristics): measure of how much the model is capable of distinguishing between classes. The higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"NaiveBayes\", \"RF_BOW\", \"RF_BPOS\", \"RF_EMB\", \"ADA_BOW\", \"ADA_BPOS\", \"ADA_EMB\", \n",
    "              \"XGB_BOW\", \"XGB_BPOS\", \"XGB_EMB\"]\n",
    "\n",
    "accuracy = dict()\n",
    "for n in range(len(model_names)): \n",
    "    accuracy[model_names[n]] = acc[n]\n",
    "\n",
    "auc_roc = dict()\n",
    "for n in range(len(model_names)): \n",
    "    auc_roc[model_names[n]] = auc_res[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "plt.xlabel('Accuracy')\n",
    "keys = accuracy.keys()\n",
    "values = accuracy.values()\n",
    "\n",
    "plt.bar(keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "plt.xlabel('AUC ROC')\n",
    "keys = auc_roc.keys()\n",
    "values = auc_roc.values()\n",
    "\n",
    "plt.bar(keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
